---

layout: single  
title: "kafka简介"  
date: 2022-06-01 17:19:00 +0800   
categories: kafka

---

# kafka技术实现

* kafka是一款开源的**消息引擎**系统，也是一个分布式流处理平台（Distributed Streaming Platform）。
* 消息引擎系统是一组**规范**。企业利用这组规范在不同系统之间**传递语义准确的消息**，实现松耦合的**异步式数据传递**。
* 设计消息引擎需要解决两个主要问题：
	* 消息的编码格式：json等
	* 消息的传输协议，比如点对点模型（也叫消息队列模型），发布/订阅模型 。
* 消息引擎系统的一大作用：削峰填谷。
* kafka高可用性：
	* kafka集群的多个broker进程 
	* 备份机制：领导者副本（读写），追随者副本（只备份，不可读）
* kafka伸缩性：
	* 分片：即主题的分区
* kafka持久化：
	* 消息日志（Log）保存数据，分为多个日志段。日志段由一系列消息集合日志项组成，消息集合中包含若干条日志项（record item），而日志项封装消息。
*  kafka I/O 模型使用Linux 上的 epoll机制，即I/O多路复用的升级。
* 在 Linux 部署 Kafka 能够享受到**零拷贝**技术所带来的快速数据传输特性。
* Kafka 采用 TCP 协议作为所有请求通信的底层协议。
* 消费者组，指的是**多个消费者实例**共同组成一个组来消费**一组**主题。 （为了提升消费者端的吞吐量）
* “重平衡”（Rebalance）：为消费者组内的消费者实例重新分配分区，在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。
* Kafka 使用 Consumer Group 这一种机制，同时实现了传统消息引擎系统的两大模型：如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型。
*  Consumer Group 的位移信息保存在 Kafka 内部主题：__consumer_offsets。
*  同Consumer Group一样，Consumer也有Group ID 来标识它自己。
*  __consumer_offsets存储消息格式种类：
	*  消息的键值和消息体，即KV 对，键格式：<Group ID，主题名，分区号 >，消息体：位移值。
	*  用于保存 Consumer Group 信息的消息。（注册 Consumer Group）
	*  用于删除 Group 过期位移甚至是删除 Group 的消息。（消息体为空）
* Coordinator，它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。所有 Broker 都有各自的 Coordinator 组件。
* Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤：
	* 第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。
	* 第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。
* Coordinator 通知各个 Consumer 实例开启 Rebalance 的方法，就是将 REBALANCE_NEEDED 标志封装进心跳请求的响应体中。 
* 手动提交：
	* commitSync()：阻塞 
	* commitAsync() ：不会阻塞，提供了回调函数，但不会自动重试。
* Consumer Lag表示消费者的已消费消息数-生产者生产的消息数，Lag是分区级别的。
* 如果消费者的速度无法匹及生产者的速度，极有可能导致它消费的数据已经不在操作系统的页缓存中了，从而需要从磁盘中获取。

# kafka客户端

## 生产者

### 生产者参数配置

* 生产者设置分区策略参数：默认轮询策略（Round-robin），常用有随机，按消息键保序等，或者根据接口实现自定义分区策略。（分区的作用就是提供负载均衡与实现系统的高伸缩性（Scalability）
* 生产者设置消息压缩算法：比如gzip，zstd ， LZ4 ， GZIP ， Snappy。
* 生产者发送消息：异步发送，即发送后直接返回，不管结果是否成功（解决：增加回调，回调无法解决网络抖动） 
* 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。
* 设置 retries 为一个较大的值（可以解决网络抖动）。
* bootstrap.servers：Broker 地址列表
* metadata.max.age.ms：定期地去更新元数据信息。该参数的默认值是 300000，即 5 分钟。
* enable.idempotence：设置幂等性（+重试+回调，保证了消息不会丢失，也不会被重复发送）
* transactional. id：设置事务id （+enable.idempotence = true，实现多分区上的幂等性和跨会话的幂等性）
* connections.max.idle.ms：默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个 TCP 连接，那么 Kafka 生产者会主动帮你把该 TCP 连接关闭。connection.max.idle.ms 设置成 -1，可能会产生“僵尸”连接。

### Java客户端生产者创建TCP连接与关闭连接

* 第一次TCP连接：在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与参数bootstrap.servers中的Broker地址列表的TCP连接，发送
METADATA 请求，尝试获取集群的元数据信息。
* 第二次TCP连接：KafkaProducer 实例在第一TCP连接更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。
* 新的TCP连接：
	* Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。
	* 当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。
* Kafka 支持强制将空闲的 TCP 连接资源关闭。
* 关闭 TCP 连接：
	* 用户主动关闭：producer.close()
	* Kafka 自动关闭：配置参数connections.max.idle.ms

## 消费者

### 消费者参数设置

* enable.auto.commit：true（自动提交或者叫异步提交，可能问题：消息重复），false（手动提交或者叫同步提交，会阻塞，可能问题：消息丢失，最好采用手动提交）
* auto.commit.interval.ms：自动提交间隔
*  isolation.level：
	* read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。很显然，如果你用了事务型 Producer，那么对应的 Consumer 就不要使用这个值。
	* read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然了，它也能看到非事务型 Producer 写入的所有消息。
* session.timeout.ms：Coordinator认为消费者实例挂了的没有收到心跳请求的时间段，默认值是 10 秒
* heartbeat.interval.ms：向Coordinator 发送心跳请求间隔。
* max.poll.interval.ms ：限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔，默认值是 5 分钟。表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。
* connections.max.idle.ms：默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个 TCP 连接，那么 Kafka 消费者会主动帮你把该 TCP 连接关闭。connection.max.idle.ms 设置成 -1，可能会产生“僵尸”连接。

### Java客户端多线程异步处理消费消息方案 

* 一般采用手动提交。
* 多个线程间在如何处理位移提交这个问题上容易出错。
* KafkaConsumer双线程的设计，即用户主线程和心跳线程。
* KafkaConsumer 类不是线程安全的 (thread-safe)。
* 方案一：消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程。
* 方案二：消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。

### Java客户端消费者创建TCP连接与关闭连接

* 构建 KafkaConsumer 实例时是不会创建任何 TCP 连接的，TCP 连接是在调用 KafkaConsumer.poll 方法时被创建的。
* 第一次TCP连接或者第一类TCP连接：先发送id=-1的连接请求，再发送获取元数据的请求，最后发送FIND_COORDINATOR请求。（获取集群元数据和确定协调者）
* 第二次TCP连接或者第二类TCP连接：发送id=Integer.MAX_VALUE-brokerid的连接请求（连接协调者）
* 第三次TCP连接或者第三类TCP连接：发送id=brokerid的连接请求（为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP，执行实际的消息获取）
* 当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。
* 关闭 TCP 连接：
	* 手动关闭：KafkaConsumer.close() 
	* kafka自动关闭：配置参数connections.max.idle.ms

# kafka服务端

## 参数配置

### broker配置文件 server.properties常用参数（重启Broker 进程才能生效）

* broker级别的参数：
	* log.dirs：消息存储路径参数
	* zookeeper.connect（ zookeeper协调管理并保存 Kafka 集群的所有元数据信息）
	* listeners
	* advertised.listeners
	* auto.create.topics.enable：是否允许自动创建 Topic。
	* unclean.leader.election.enable：是否允许 Unclean Leader 选举，默认false。
	* auto.leader.rebalance.enable：是否允许定期进行 Leader 选举。
	* log.retention.`{hours|minutes|ms}`：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低。
	* log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。
	* message.max.bytes：控制 Broker 能够接收的最大消息大小。
	* replication.factor ：副本数，一般>=3。
	* min.insync.replicas ：消息至少要被写入到多少个副本才算是“已提交”，默认为1，但一般设置>1。（推荐设置成 replication.factor = min.insync.replicas + 1。）
	* offsets.topic.num.partitions：位移主题的分区数，默认值是 50。
	* offsets.topic.replication.factor：位移主题副本数。它的默认值是 3。

### kafka提供的shell脚本配置参数

* topic级别的参数（创建 Topic 时进行设置：bin/kafka-topics.sh，或者修改 Topic 时设置：bin/kafka-configs.sh）
	* retention.ms
	* retention.bytes
	* max.message.bytes

### JVM 参数

* 环境变量设置：
	* KAFKA_HEAP_OPTS：指定堆大小。
	* KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。 

### 操作系统参数

* 文件描述符限制
* 文件系统类型
* Swappiness
* Flush 落盘时间：数据被写入到操作系统的页缓存（Page Cache），随后操作系统根据 LRU 算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。

## Broker进程

* broker重新压缩消息的情况：
	* Broker 端指定了和 Producer 端不同的压缩算法
	* Broker 端发生了消息格式转换，即消息版本问题
* Broker 端解压缩：对消息执行各种验证。





